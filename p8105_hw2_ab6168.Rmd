---
title: "p8105_hw2_ab6168"
output: github_document
date: "2025-09-24"
---
Angelica Bailey


```{r setup, echo=FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```


## Problem 1

Cleaning pols_month dataframe
```{r}
pols_month_df = 
  read_csv("data/pols-month.csv") |> 
  #breaking up date variable
  separate(mon,
    into = c("year", "month","day"), sep = "-") |> 
  #converting month name to number
  mutate(year = as.numeric(year),
    month = case_match(
      month,
      "01" ~ "jan",
      "02" ~ "feb",
      "03" ~ "mar",
      "04" ~ "apr",
      "05" ~ "may",
      "06" ~ "jun",
      "07" ~ "jul",
      "08" ~ "aug",
      "09" ~ "sep",
      "10" ~ "oct",
      "11" ~ "nov",
      "12" ~ "dec"),
    #creating new variable to take on dem (0) and gop (1).
    prez_gop = case_match(
      prez_gop,
      0 ~ "dem",
      1 ~ "gop"
    ),
    president = prez_dem) |> 
  select(-day,-prez_gop,-prez_dem)



#cleaning snp dataframe
snp_df = 
  read_csv("data/snp.csv") |> 
  separate(date,
    into = c("month", "day","year"), sep = "/") |> 
  #reformatting year
  mutate(year = as.numeric(year),
         year = case_when(
           year > 15 ~ year + 1900,
           year <= 15 ~ year + 2000
         ),
         month = case_match(
           month,
           "1" ~ "jan",
           "2" ~ "feb",
           "3" ~ "mar",
           "4" ~ "apr",
           "5" ~ "may",
           "6" ~ "jun",
           "7" ~ "jul",
           "8" ~ "aug",
           "9" ~ "sep",
           "10" ~ "oct",
           "11" ~ "nov",
           "12" ~ "dec")
        ) |> 
  select(-day) |> 
  relocate(year)



#cleaning unemployment dataframe
unemployment_df = 
  read_csv("data/unemployment.csv") |> 
  #switching from wide to long format
  pivot_longer(
    cols = Jan:Dec,
    names_to = "month",
    values_to = "per_unemp"
  ) |> 
  mutate(month = tolower(month), 
           year = Year) |> 
  select(-Year) |> 
  relocate(year)


```


**Joining datasets**

```{r}
#merging `pols` and `snp` datasets
pols_snp_df =
  left_join(pols_month_df, snp_df, by = c("year","month"))

#merging `unemployment` with result
fte_df =
  left_join(pols_snp_df, unemployment_df, by = c("year","month"))
```

**Description**

The `pols_month_df` dataset shows the number of national politicians who are democratic or republican at any given time. It contains the number of republican governors, senators, and representatives on the associated date as well as on the democratic side. The `snp` dataset shows the closing values of the Standard & Poor's stock market index on the associated date. Lastly, the `unemployment` dataset displays percentages of unemployment by month and year. After joining these datasets, the resulting dataset has 113,124 rows and 13 columns. The total range of years is from 1947 to 2015. The key variables of the dataset include `president`,`close`, `per_unmep`. 


## Problem 2

Reading and cleaning excel files
```{r}
#cleaning MrTrash file
mr_trash_df = 
  read_excel("data/trash-wheel.xlsx", sheet = "Mr. Trash Wheel") |> 
  #removing empty columns
  select(-...15,-...16) |> 
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards") |> 
  filter(row_number() <= n() - 2) |>
  mutate(sports_balls = as.integer(round(sports_balls)),
         year = as.integer(year),
         wheel_name = "mr_trash")



#cleaning ProfessorTrash file  
prof_trash_df = 
  read_excel("data/trash-wheel.xlsx", sheet = "Professor Trash Wheel") |>
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards") |> 
  filter(row_number() <= n() - 3) |> 
  mutate(wheel_name = "professor_trash")



#cleaning GwynndaTrash file
gwyn_trash_df =
  read_excel("data/trash-wheel.xlsx", sheet = "Gwynnda Trash Wheel") |> 
  janitor::clean_names() |> 
  rename(
    weight = "weight_tons",
    volume = "volume_cubic_yards") |> 
  filter(row_number() <= n() - 1) |> 
  mutate(wheel_name = "gwynnda_trash")

```


Binding datasets
```{r}
trash_wheel_df =
  bind_rows(mr_trash_df, prof_trash_df, gwyn_trash_df) |> 
  relocate(wheel_name)
```



Filtering Gywnnda dataset to June 2022
```{r}
june2022_gwyn = filter(gwyn_trash_df, month == "June" & year == 2022)
```


**Description**

There are `r nrow(trash_wheel_df)` observations in the resulting dataset. Among the variables, the total weight of trash collected by Professor Trash Wheel is `r sum(prof_trash_df$weight)` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 is  `r sum(june2022_gwyn$cigarette_butts)`. 



##Problem 3
Create a single, well-organized dataset with all the information contained in these data files. To that end: import, clean, tidy, and otherwise wrangle each of these datasets; check for completeness and correctness across datasets (e.g. by viewing individual datasets and monitoring warning messages); merge to create a single, final dataset; and organize this so that variables and observations are in meaningful orders.



```{r}
#reading in csv files
zip_df = 
  read_csv("data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  #filtering duplicated rows
  filter(row_number() != 226) |> 
  filter(row_number() != 226)


zori_df =
  read_csv("data/zori_NYC.csv") |> 
  select(-StateName,-Metro,-RegionType) |> 
  #renaming variables
  rename(
    region_id = "RegionID",
    size_rank = "SizeRank",
    zip_code = "RegionName",
    state = "State",
    city = "City",
    county_name = "CountyName") |> 
  pivot_longer(
    cols = "2015-01-31":"2024-08-31",
    names_to = "date",
    values_to = "rent_prices"
  )

```


Creating tidy dataset

```{r}
#joining datasets
zori_zip_df =
  left_join(zip_df, zori_df, by = "zip_code") |> 
  select(-county_name,-file_date,-state,-city,-state_fips) |> 
  relocate(county_code, county_fips, zip_code, neighborhood, .after = county)
  
```

**Description**

From the resulting tidy dataset, there are a total of `r nrow(zori_zip_df)` observations. There are 320 unique zip codes and 42 unique neighborhoods. There are many missing values in the rental prices dataset. 

Some ZIP codes might not be shown in the Zillow dataset because there may be very few rental properties in those zip codes.

Comparing rental prices
```{r}
#filtering to January 2020 and 2021
jan_data <- zori_zip_df |> 
  filter(date == c("2020-01-31","2021-01-31"))
```


Creating table

```{r}

```

knitr::kable() 


11226
11226




